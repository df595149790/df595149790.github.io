

###  百度 enrie 交流

* 知识库，只是包括分词信息，不包括其他逻辑信息，希望通过学习获得
* 单词的mask，没有特别包括单字的mask，因为分词时会将有意义的单字列出来，没有意义的单字，不考虑
* 分词库的准确性，还可以，分词错误，对于模型准确性确实有影响
* pre-train的任务，是enrie完成的，用户fine-tune任务
* 目前pre-train的任务代码，没有开源，如果需要增加新的分词，需要百度改进，或者，作为fine-tune的任务？


