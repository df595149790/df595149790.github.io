
## NLP 思考

### 模型到底是什么

NLP模型核心的问题，是要解决输入与输出的匹配问题，为了达到这个目标，使用了很多技术手段，其核心过程是通过计算机运算，得到转换时的参数。那么，数学在里边起到什么作用？数学的意义，是在于从整体上进行分析，并指导编程。

这篇文章解释的不错：[XLNet原理解读](https://blog.csdn.net/weixin_37947156/article/details/93035607)

主要的模型，区别如下

* GPT

  基于时序的思路，即所谓自回归AR（AutoRegressive），将句子中的单词，与前面出现的单词，和后面出现的单词，关联起来。
在预测时，可以根据前面或者后面出现的单词，得到紧接着要出现的单词。

* BERT

  基于编码的思路，即所谓自编码AE（AutoEncoder），将句子中的某些单词，编码到句子整体中，只考虑空间结构，不考虑时间顺序。
在预测时，根据已经出现的单词组成的空间结构，得到最合适的单词。

* XLNet

  也是编码思路，但是与BERT的差别在于，具体训练过程中的手段不同，没有采用BERT的Mask方式，而是从所有排列组合中，寻找最大的可能方式，同时，保持了前向的时序特征。因此，它算是AE+AR的模式。
在预测时，与BERT类似。

* ERINE

  编码思路，是对于BERT的微调，即增加了对于单词的处理，不再是单词（Word），而是短语（Phrase），从而避免了无效Word的关联，是对于空间结构的优化。
在预测时，与BERT类似。

这段话语挺有趣：

>分布式语义假设的局限性在哪里？根据符号关联假设 (Symbol Interdependency Hypothesis)[5]，虽然语境的统计信息可以构建出符号之间的关系，从而确定其相对语义。但我们仍需要确定语言符号与现实世界的关系 (Language Grounding)，让我们的 AI 系统知道，「红色」对应的是红色，「天空」对应的是天空，「国家」对应的是国家。这种对应信息是通过构建知识库，还是通过和视觉、语音系统的联合建模获得？解决这一问题可能是下一大新闻的来源，也能将我们往 AI 推进一大步。

目前这些模型，解决语义问题的思路，都是去学习这些内容，不会接入外部的知识图谱。这种方式存在的问题时，逻辑上并不一致，特别是涉及到推理逻辑关系时，会存在矛盾。此时，或者，表征同一概念的实体，需要统一ID，表示同一个概念，或者，分裂为不同的实体，表示逻辑上就是不一样的概念。
这种方式，可以推理一下，不同的数据训练出来的参数，会不一样，即导致偏见。应该讲，这种偏见不可避免，因为所谓概念，本身就是人类对于物理世界的映射，概念上无法唯一。当然，我们也可以结合视觉，来建立NLP实体的语义指向。但是，这种方式不能解决所有的实体语义，而且，依然存在数据偏见。





